{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "\n",
    "import pickle\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'SR':20000,\n",
    "    'N_melspectrogram':30, # Melspectogram 벡터를 추출할 개수\n",
    "    'N_MFCC':32, # MFCC 벡터를 추출할 개수\n",
    "    'SEED':41\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_data_path = 'audio_data'\n",
    "audio_train_data_path = os.path.join(audio_data_path,'train')\n",
    "audio_test_data_path = os.path.join(audio_data_path,'test')\n",
    "train_df = pd.read_csv(os.path.join(audio_data_path,'train.csv'))\n",
    "test_df = pd.read_csv(os.path.join(audio_data_path,'test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mel_feature(df, data_type, save_path):\n",
    "    # Data Folder path\n",
    "    root_folder = './audio_data'\n",
    "    if os.path.exists(save_path):\n",
    "        print(f'{save_path} is exist.')\n",
    "        return\n",
    "    features = []\n",
    "    features2 = []\n",
    "    for uid in tqdm(df['SegmentId']):\n",
    "        root_path = os.path.join(root_folder, data_type)\n",
    "        uid += '.wav'\n",
    "        path = os.path.join(root_path, uid)\n",
    "\n",
    "        # librosa패키지를 사용하여 wav 파일 load\n",
    "        y, sr = librosa.load(path, sr=CFG['SR'])\n",
    "    \n",
    "        \n",
    "        melspectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=CFG['N_melspectrogram'])\n",
    "        \n",
    "        \n",
    "        # log sccale로 변환\n",
    "        feature1 = librosa.power_to_db(S=melspectrogram, ref=1.0)\n",
    "\n",
    "        # feature1 : 추출된 melspectrogram들의 평균을 Feature로 사용\n",
    "        y_feature1 = []\n",
    "        for e in feature1:\n",
    "            y_feature1.append(np.mean(e))    \n",
    "            \n",
    "        features.append(y_feature1)\n",
    "        \n",
    "        \n",
    "   \n",
    "    mel_df = pd.DataFrame(features, columns=['mel_'+str(x) for x in range(1,CFG['N_melspectrogram']+1)])\n",
    "    df = pd.concat([df, mel_df_norm], axis=1)\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  mel + mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mel_feature2(df, data_type, save_path):\n",
    "    # Data Folder path\n",
    "    root_folder = './audio_data'\n",
    "    if os.path.exists(save_path):\n",
    "        print(f'{save_path} is exist.')\n",
    "        return\n",
    "    features = []\n",
    "    features2 = []\n",
    "    for uid in tqdm(df['SegmentId']):\n",
    "        root_path = os.path.join(root_folder, data_type)\n",
    "        uid += '.wav'\n",
    "        path = os.path.join(root_path, uid)\n",
    "\n",
    "        # librosa패키지를 사용하여 wav 파일 load\n",
    "        y, sr = librosa.load(path, sr=CFG['SR'])\n",
    "    \n",
    "        # melspectrogram\n",
    "        melspectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=CFG['N_melspectrogram'])\n",
    "        # mfcc\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=CFG['N_MFCC'])\n",
    "        \n",
    "        \n",
    "        # log sccale로 변환\n",
    "        feature1 = librosa.power_to_db(S=melspectrogram, ref=1.0)\n",
    "\n",
    "        # feature1 : 추출된 melspectrogram들의 평균을 Feature로 사용\n",
    "        y_feature1 = []\n",
    "        for e in feature1:\n",
    "            y_feature1.append(np.mean(e))    \n",
    "            \n",
    "        features.append(y_feature1)\n",
    "        \n",
    "        \n",
    "        y_feature2 = []\n",
    "        # 추출된 MFCC들의 평균을 Feature로 사용\n",
    "        for e in mfcc:\n",
    "            y_feature2.append(np.mean(e))\n",
    "        features2.append(y_feature2)\n",
    "    \n",
    "\n",
    "    \n",
    "    mel_df = pd.DataFrame(features, columns=['mel_'+str(x) for x in range(1,CFG['N_melspectrogram']+1)])\n",
    "    mfcc_df = pd.DataFrame(features2, columns=['mfcc_'+str(x) for x in range(1,CFG['N_MFCC']+1)])\n",
    "    df = pd.concat([df, mel_df,mfcc_df], axis=1)\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78c193bed3bd430e8882140384eed429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10769.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_mel_feature(train_df, 'train', 'preprocessing_data/train_mel_data.csv')\n",
    "get_mel_feature(test_df, 'test', 'preprocessing_data/test_mel_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# wav 파일의 MFCC Feature와 상태정보를 합친 학습데이터를 불러옵니다.\n",
    "train_df = pd.read_csv('preprocessing_data/train_mel_data.csv')\n",
    "test_df = pd.read_csv('preprocessing_data/test_mel_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습데이터를 모델의 input으로 들어갈 x와 label로 사용할 y로 분할\n",
    "train_x = train_df.drop(columns=['Unnamed: 0', 'SegmentId','time','Valence','Arousal','Emotion'])\n",
    "train_y = train_df['Emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier(random_state=CFG['SEED']) # Sklearn에서 제공하는 Multi-layer Perceptron classifier 사용\n",
    "model.fit(train_x, train_y) # Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위의 학습데이터를 전처리한 과정과 동일하게 test data에도 적용\n",
    "test_x = test_df.drop(columns=['Unnamed: 0', 'SegmentId','time','Valence','Arousal','Emotion'])\n",
    "test_y = test_df['Emotion']\n",
    "\n",
    "# Model 추론\n",
    "preds = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "\n",
    "# Accuracy를 계산하여 성능을 평가합니다.\n",
    "accuracy = accuracy_score(test_y, preds)\n",
    "\n",
    "print(f\"[mel] 모델의 성능(Accuracy): {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mfcc+mel Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mfcc + mel] 모델의 성능(Accuracy): 0.8403267731154845\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "\n",
    "# Accuracy를 계산하여 성능을 평가합니다.\n",
    "accuracy = accuracy_score(test_y, preds)\n",
    "\n",
    "print(f\"[mfcc + mel] 모델의 성능(Accuracy): {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = './model/classification_mel_0_84_model.pkl' # Accuracy 0.84 model save\n",
    "# pickle.dump(model, open(filename,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
