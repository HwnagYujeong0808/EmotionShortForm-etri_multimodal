{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: cp949 -*-\n",
    "from glob import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2Model\n",
    "import argparse\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--dataset', type=int, default=19)\n",
    "# parser.add_argument('--dataset_dir', type=str, default='./KEMDy19/')\n",
    "# parser.add_argument('--ckpt', type=str, default='0', help='checkpoint')\n",
    "# parser.add_argument('--num_fold', type=int, default=5)\n",
    "# parser.add_argument('--lr', type=float, default=1e-5, help='learning_rate')\n",
    "# parser.add_argument('--batch_size', type=int, default=32, help='batch_size')\n",
    "# parser.add_argument('--gpus', type=str, default='0', help='gpu numbers')\n",
    "# parser.add_argument('--epochs', type=int, default=5, help='epochs')\n",
    "# parser.add_argument('--max_seq_len', type=int, default=5, help='max sequence length of speech')\n",
    "# parser.add_argument('--num_labels', type=int, default=7, help='num_labels')\n",
    "# parser.add_argument('--regress', type=int, default=1, help='regression (0-1)')\n",
    "# parser.add_argument('--seed', type=int, default=1234, help='seed')\n",
    "# args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "# 주피터 노트북에서 명령행 인자 대신 변수를 직접 설정합니다.\n",
    "args = argparse.Namespace()\n",
    "args.dataset = 20\n",
    "args.dataset_dir = './data_audio/'\n",
    "args.ckpt = '0'\n",
    "args.num_fold = 1\n",
    "args.lr = 1e-5\n",
    "args.batch_size = 1\n",
    "args.gpus = '0'\n",
    "args.epochs = 5\n",
    "args.max_seq_len = 5\n",
    "args.num_labels = 7\n",
    "args.regress = 1\n",
    "args.seed = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = args.gpus\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seed\n",
    "if args.seed is not None:\n",
    "    import random\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "    torch.cuda.manual_seed_all(args.seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loader\n",
    "class SpectrogramDataset(Dataset):\n",
    "    def __init__(self, path_list, max_seq_len):\n",
    "        super(SpectrogramDataset, self).__init__()\n",
    "        # [0] = wav, [1] = txt, [2] = emo_label, [3] = valence, [4] = arousal\n",
    "        self.wav_list = path_list[0]\n",
    "        self.txt_list = path_list[1]\n",
    "        self.label_list = path_list[2]\n",
    "        self.valence_list = path_list[3]\n",
    "        self.arousal_list = path_list[4]\n",
    "        self.size = len(self.wav_list)\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        try:        \n",
    "            wav_data, based_sr = torchaudio.load(self.wav_list[index])            \n",
    "        except:\n",
    "            print('data {} has problem, can not reading '.format(self.wav_list[index]))\n",
    "            return None\n",
    "        \n",
    "        if wav_data.size(-1) > self.max_seq_len:\n",
    "            wav_data = wav_data[:, :self.max_seq_len]\n",
    "        \n",
    "        #input_dict = tokenizer(self.txt_list[index], padding = 'max_length', max_length = args.max_text_len, return_tensors = 'pt', return_attention_mask = False)\n",
    "        #output_text = torch.cat([input_dict['input_ids'], input_dict['token_type_ids'], ~(input_dict['input_ids']==0)], dim=0)\n",
    "        \n",
    "        return wav_data, self.label_list[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _collate_fn(batch):    \n",
    "    batches = list(filter(lambda x: x is not None, batch))\n",
    "    batch = sorted(batches, key=lambda sample: sample[0].size(1), reverse=True)\n",
    "    \n",
    "    seq_lengths = [s[0].size(1) for s in batch]\n",
    "    max_seq_size = max(seq_lengths)\n",
    "    \n",
    "    seqs = torch.zeros(len(batch), max_seq_size)\n",
    "    targets = torch.zeros(len(batch), 7).to(torch.long)\n",
    "    \n",
    "    for x in range(len(batch)):\n",
    "        sample = batch[x]\n",
    "        tensor = sample[0]\n",
    "        target = sample[1]\n",
    "        seq_length = tensor.size(1)\n",
    "        seqs[x].narrow(0, 0, seq_length).copy_(tensor.squeeze())\n",
    "        targets[x].narrow(0, 0, len(target)).copy_(target)\n",
    "    \n",
    "    return seqs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataLoader(DataLoader):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(AudioDataLoader, self).__init__(*args, **kwargs)\n",
    "        self.collate_fn = _collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "wav_dir = os.path.join(args.dataset_dir, 'wav')\n",
    "label_df = sorted(glob(os.path.join(args.dataset_dir, 'annotation', '*')))\n",
    "\n",
    "all_wav = []\n",
    "all_txt = []\n",
    "all_emotion = []\n",
    "all_valence = []\n",
    "all_arousal = []\n",
    "bad_data_for_20 = 0\n",
    "bad_data_for_19 = 0\n",
    "\n",
    "emotion_dict = {\"angry\": 0, \"disqust\": 1, \"fear\": 2, \"happy\": 3, \"neutral\": 4, \"sad\": 5, \"surprise\": 6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad for 20 0\n",
      "bad for 19 0\n"
     ]
    }
   ],
   "source": [
    "for d in range(len(label_df)):    \n",
    "    _, file_tmp = os.path.split(label_df[d])\n",
    "    file_num = file_tmp.split('_')[0]\n",
    "    \n",
    "    usecols_element = [3, 4, 5, 6] if args.dataset == 20 else [9, 10, 11, 12]\n",
    "    df = pd.read_csv(label_df[d], usecols=usecols_element, skiprows=[0])\n",
    "    \n",
    "    val_list = df.values.tolist()\n",
    "    \n",
    "    for i in range(len(val_list)):\n",
    "    \n",
    "        if args.dataset == 20:\n",
    "            first_folder = val_list[i][0].split('_')[0]\n",
    "            if file_num != first_folder and file_num == 'Sess17':\n",
    "                first_folder = 'Sess17'\n",
    "                first_folder_tmp = first_folder[:-2]+'ion'+first_folder[-2:]\n",
    "                direc = os.path.join(wav_dir, first_folder_tmp)\n",
    "                    \n",
    "                wav_file = os.path.join(direc, first_folder+val_list[i][0][6:]+'.wav')\n",
    "                txt_file = os.path.join(direc, first_folder+val_list[i][0][6:]+'.txt')\n",
    "                   \n",
    "            else:\n",
    "                first_folder_tmp = first_folder[:-2]+'ion'+first_folder[-2:]\n",
    "                direc = os.path.join(wav_dir, first_folder_tmp)\n",
    "                wav_file = os.path.join(direc, val_list[i][0]+'.wav')\n",
    "                txt_file = os.path.join(direc, val_list[i][0]+'.txt')\n",
    "        \n",
    "            if os.path.isfile(wav_file) and os.path.isfile(txt_file):\n",
    "            \n",
    "                emotion = val_list[i][1]\n",
    "                val = val_list[i][2]\n",
    "                aro = val_list[i][-1]\n",
    "                \n",
    "                all_wav.append(wav_file)\n",
    "                with open(txt_file, 'r', encoding='cp949') as f:\n",
    "                    infor = f.readline()\n",
    "                    infor = infor.split('\\n')[0]\n",
    "                all_txt.append(infor)\n",
    "                all_emotion.append(emotion)\n",
    "                all_valence.append(val)\n",
    "                all_arousal.append(aro)\n",
    "            else:\n",
    "                bad_data_for_20 += 1\n",
    "    \n",
    "    \n",
    "        elif args.dataset == 19:\n",
    "            first_folder = val_list[i][0].split('_')[0]\n",
    "            first_folder_tmp = first_folder[:-2]+'ion'+first_folder[-2:]\n",
    "            direc = os.path.join(wav_dir, first_folder_tmp)\n",
    "            speaker_num = val_list[i][0][:-5]\n",
    "\n",
    "            wav_file = os.path.join(direc, speaker_num, val_list[i][0]+'.wav')\n",
    "            txt_file = os.path.join(direc, speaker_num, val_list[i][0]+'.txt')\n",
    "            \n",
    "            if os.path.isfile(wav_file) and os.path.isfile(txt_file):\n",
    "                \n",
    "                emotion = val_list[i][1]\n",
    "                val = val_list[i][2]\n",
    "                aro = val_list[i][-1]\n",
    "                all_wav.append(wav_file)\n",
    "                \n",
    "                with open(txt_file, 'r') as f:\n",
    "                    infor = f.readline()\n",
    "                    infor = infor.split('\\n')[0]\n",
    "                all_txt.append(infor)\n",
    "                all_emotion.append(emotion)\n",
    "                all_valence.append(val)\n",
    "                all_arousal.append(aro)\n",
    "            else:\n",
    "                bad_data_for_19 +=1\n",
    "\n",
    "print('bad for 20', bad_data_for_20)\n",
    "print('bad for 19', bad_data_for_19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making label as multi-label classification\n",
    "make_label = torch.FloatTensor(len(all_emotion), 7).random_(1)\n",
    "for k in range(len(all_emotion)):\n",
    "    data_tmp = all_emotion[k]\n",
    "    if len(data_tmp.split(';')) == 1:\n",
    "        make_label[k][emotion_dict.get(data_tmp)] = 1.\n",
    "        \n",
    "    else:\n",
    "        for j in range(len(data_tmp.split(';'))):\n",
    "            make_label[k][emotion_dict.get(data_tmp.split(';')[j])] = 1.\n",
    "            \n",
    "#print(len(all_wav), len(all_txt), len(make_label), len(all_valence), len(all_arousal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of train_fold 5 wav 10770 emo 10770\n",
      "fold = 1, training wav 10770 txt 10770 emo 10770 val 10770 aro 10770\n",
      "test wav 1 txt 2692 emo 2692 val 2692 aro 2692\n"
     ]
    }
   ],
   "source": [
    "## cut as k-fold\n",
    "if args.num_fold == 1:    \n",
    "    train_wav = all_wav[int(len(all_wav)*0.2):]\n",
    "    train_txt = all_txt[int(len(all_wav)*0.2):]\n",
    "    train_emo_label = make_label[int(len(all_wav)*0.2):]\n",
    "    train_valence_label = all_valence[int(len(all_wav)*0.2):]\n",
    "    train_arousal_label = all_arousal[int(len(all_wav)*0.2):]\n",
    "    \n",
    "    test_wav = all_wav[:int(len(all_wav)*0.2)]\n",
    "    test_txt = all_txt[:int(len(all_wav)*0.2)]\n",
    "    test_emo_label = make_label[:int(len(all_wav)*0.2)]\n",
    "    test_valence_label = all_valence[:int(len(all_wav)*0.2)]\n",
    "    test_arousal_label = all_arousal[:int(len(all_wav)*0.2)]\n",
    "    \n",
    "    \n",
    "elif args.num_fold == 2:\n",
    "    train_wav = all_wav[:int(len(all_wav)*0.2)] + all_wav[int(len(all_wav)*0.4):]\n",
    "    train_txt = all_txt[:int(len(all_wav)*0.2)] + all_txt[int(len(all_wav)*0.4):]\n",
    "    train_emo_label = torch.cat((make_label[:int(len(all_wav)*0.2)],make_label[int(len(all_wav)*0.4):]))\n",
    "    train_valence_label = all_valence[:int(len(all_wav)*0.2)] + all_valence[int(len(all_wav)*0.4):]\n",
    "    train_arousal_label = all_arousal[:int(len(all_wav)*0.2)] + all_arousal[int(len(all_wav)*0.4):]\n",
    "    \n",
    "    test_wav = all_wav[int(len(all_wav)*0.2):int(len(all_wav)*0.4)]\n",
    "    test_txt = all_txt[int(len(all_wav)*0.2):int(len(all_wav)*0.4)]\n",
    "    test_emo_label = make_label[int(len(all_wav)*0.2):int(len(all_wav)*0.4)]\n",
    "    test_valence_label = all_valence[int(len(all_wav)*0.2):int(len(all_wav)*0.4)]\n",
    "    test_arousal_label = all_arousal[int(len(all_wav)*0.2):int(len(all_wav)*0.4)]\n",
    "    \n",
    "elif args.num_fold == 3:\n",
    "    train_wav = all_wav[:int(len(all_wav)*0.4)] + all_wav[int(len(all_wav)*0.6):]\n",
    "    train_txt = all_txt[:int(len(all_wav)*0.4)] + all_txt[int(len(all_wav)*0.6):]\n",
    "    train_emo_label = torch.cat((make_label[:int(len(all_wav)*0.4)],make_label[int(len(all_wav)*0.6):]))\n",
    "    train_valence_label = all_valence[:int(len(all_wav)*0.4)] + all_valence[int(len(all_wav)*0.6):]\n",
    "    train_arousal_label = all_arousal[:int(len(all_wav)*0.4)] + all_arousal[int(len(all_wav)*0.6):]\n",
    "    \n",
    "    test_wav = all_wav[int(len(all_wav)*0.4):int(len(all_wav)*0.6)]\n",
    "    test_txt = all_txt[int(len(all_wav)*0.4):int(len(all_wav)*0.6)]\n",
    "    test_emo_label = make_label[int(len(all_wav)*0.4):int(len(all_wav)*0.6)]\n",
    "    test_valence_label = all_valence[int(len(all_wav)*0.4):int(len(all_wav)*0.6)]\n",
    "    test_arousal_label = all_arousal[int(len(all_wav)*0.4):int(len(all_wav)*0.6)]\n",
    "\n",
    "elif args.num_fold == 4:\n",
    "    train_wav = all_wav[:int(len(all_wav)*0.6)] + all_wav[int(len(all_wav)*0.8):]\n",
    "    train_txt = all_txt[:int(len(all_wav)*0.6)] + all_txt[int(len(all_wav)*0.8):]\n",
    "    train_emo_label = torch.cat((make_label[:int(len(all_wav)*0.6)],make_label[int(len(all_wav)*0.8):]))\n",
    "    train_valence_label = all_valence[:int(len(all_wav)*0.6)] + all_valence[int(len(all_wav)*0.8):]\n",
    "    train_arousal_label = all_arousal[:int(len(all_wav)*0.6)] + all_arousal[int(len(all_wav)*0.8):]\n",
    "    \n",
    "    test_wav = all_wav[int(len(all_wav)*0.6):int(len(all_wav)*0.8)]\n",
    "    test_txt = all_txt[int(len(all_wav)*0.6):int(len(all_wav)*0.8)]\n",
    "    test_emo_label = make_label[int(len(all_wav)*0.6):int(len(all_wav)*0.8)]\n",
    "    test_valence_label = all_valence[int(len(all_wav)*0.6):int(len(all_wav)*0.8)]\n",
    "    test_arousal_label = all_arousal[int(len(all_wav)*0.6):int(len(all_wav)*0.8)]\n",
    "\n",
    "elif args.num_fold == 5:\n",
    "    train_wav = all_wav[:int(len(all_wav)*0.8)]\n",
    "    train_txt = all_txt[:int(len(all_wav)*0.8)]\n",
    "    train_emo_label = make_label[:int(len(all_wav)*0.8)]\n",
    "    train_valence_label = all_valence[:int(len(all_wav)*0.8)]\n",
    "    train_arousal_label = all_arousal[:int(len(all_wav)*0.8)]\n",
    "    \n",
    "    test_wav = all_wav[int(len(all_wav)*0.8):]\n",
    "    test_txt = all_txt[int(len(all_wav)*0.8):]\n",
    "    test_emo_label = make_label[int(len(all_wav)*0.8):]\n",
    "    test_valence_label = all_valence[int(len(all_wav)*0.8):]\n",
    "    test_arousal_label = all_arousal[int(len(all_wav)*0.8):]\n",
    "train_fold = (train_wav, train_txt, train_emo_label, train_valence_label, train_arousal_label)\n",
    "test_fold = (test_wav, test_txt, test_emo_label, test_valence_label, test_arousal_label)\n",
    "print('len of train_fold {} wav {} emo {}'.format(len(train_fold), len(train_wav), len(train_emo_label)))\n",
    "\n",
    "print('fold = {}, training wav {} txt {} emo {} val {} aro {}'.format(args.num_fold, len(train_wav), len(train_txt), len(train_emo_label), len(train_valence_label), len(train_arousal_label)))\n",
    "print('test wav {} txt {} emo {} val {} aro {}'.format(args.num_fold, len(test_wav), len(test_txt), len(test_emo_label), len(test_valence_label), len(test_arousal_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2Model: ['lm_head.bias', 'lm_head.weight']\n",
      "- This IS expected if you are initializing Wav2Vec2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "wav2vec_classifier(\n",
       "  (extractor): Wav2Vec2Model(\n",
       "    (feature_extractor): Wav2Vec2FeatureEncoder(\n",
       "      (conv_layers): ModuleList(\n",
       "        (0): Wav2Vec2GroupNormConvLayer(\n",
       "          (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "          (layer_norm): GroupNorm(512, 512, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (1-4): 4 x Wav2Vec2NoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (5-6): 2 x Wav2Vec2NoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (feature_projection): Wav2Vec2FeatureProjection(\n",
       "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (projection): Linear(in_features=512, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): Wav2Vec2Encoder(\n",
       "      (pos_conv_embed): Wav2Vec2PositionalConvEmbedding(\n",
       "        (conv): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n",
       "        (padding): Wav2Vec2SamePadLayer()\n",
       "        (activation): GELUActivation()\n",
       "      )\n",
       "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x Wav2Vec2EncoderLayer(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=512, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class wav2vec_classifier(nn.Module):\n",
    "    def __init__(self, extractor, num_labels, dropout_prob=0.1):\n",
    "        super(wav2vec_classifier, self).__init__()\n",
    "\n",
    "        self.extractor = extractor\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.nu_labels = num_labels\n",
    "        self.classifier = nn.Linear(512, num_labels)\n",
    "        #self.softmax = F.softmax()\n",
    "\n",
    "    def forward(self, wav):\n",
    "        extracted_wav = self.extractor(wav)\n",
    "        \n",
    "        #last_hidden_states = extracted_wav.last_hidden_state\n",
    "        last_hidden_states = extracted_wav.extract_features\n",
    "        last_hidden_states = self.dropout(last_hidden_states)\n",
    "        output = self.classifier(last_hidden_states)\n",
    "                \n",
    "        return F.softmax(output[:, -1], dim=-1)\n",
    "\n",
    "\n",
    "extractor = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "ser_model = wav2vec_classifier(extractor, args.num_labels)\n",
    "ser_model.cuda()\n",
    "######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of train 10770 test 2692\n"
     ]
    }
   ],
   "source": [
    "#data_loader\n",
    "train_dataset = SpectrogramDataset(path_list=train_fold, max_seq_len=int(args.max_seq_len*16000))\n",
    "test_dataset = SpectrogramDataset(path_list=test_fold, max_seq_len=int(args.max_seq_len*16000))\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "\n",
    "train_dataloader = AudioDataLoader(train_dataset, batch_size=args.batch_size, shuffle=(train_sampler is None), num_workers=8, pin_memory=True, sampler=train_sampler)\n",
    "test_dataloader = AudioDataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, num_workers=8, pin_memory=True)\n",
    "print('len of train {} test {}'.format(len(train_dataloader), len(test_dataloader)))\n",
    "optimizer = AdamW(ser_model.parameters(), lr = args.lr,  eps = 1e-8)\n",
    "\n",
    "criterion = nn.MultiLabelSoftMarginLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c33c064c35b44200863e1f9ace623bb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Epoch 1 / 5 ========\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3688eae021b540878490012910d8f571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train_dataloader:   0%|          | 0/10770 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   100  of  10,770.\n",
      "  Batch   200  of  10,770.\n",
      "  Batch   300  of  10,770.\n",
      "  Batch   400  of  10,770.\n",
      "  Batch   500  of  10,770.\n",
      "  Batch   600  of  10,770.\n",
      "  Batch   700  of  10,770.\n",
      "  Batch   800  of  10,770.\n",
      "  Batch   900  of  10,770.\n",
      "  Batch 1,000  of  10,770.\n",
      "  Batch 1,100  of  10,770.\n",
      "  Batch 1,200  of  10,770.\n",
      "  Batch 1,300  of  10,770.\n",
      "  Batch 1,400  of  10,770.\n",
      "  Batch 1,500  of  10,770.\n",
      "  Batch 1,600  of  10,770.\n",
      "  Batch 1,700  of  10,770.\n",
      "  Batch 1,800  of  10,770.\n",
      "  Batch 1,900  of  10,770.\n",
      "  Batch 2,000  of  10,770.\n",
      "  Batch 2,100  of  10,770.\n",
      "  Batch 2,200  of  10,770.\n",
      "  Batch 2,300  of  10,770.\n",
      "  Batch 2,400  of  10,770.\n",
      "  Batch 2,500  of  10,770.\n",
      "  Batch 2,600  of  10,770.\n",
      "  Batch 2,700  of  10,770.\n",
      "  Batch 2,800  of  10,770.\n",
      "  Batch 2,900  of  10,770.\n",
      "  Batch 3,000  of  10,770.\n",
      "  Batch 3,100  of  10,770.\n",
      "  Batch 3,200  of  10,770.\n",
      "  Batch 3,300  of  10,770.\n",
      "  Batch 3,400  of  10,770.\n",
      "  Batch 3,500  of  10,770.\n",
      "  Batch 3,600  of  10,770.\n",
      "  Batch 3,700  of  10,770.\n",
      "  Batch 3,800  of  10,770.\n",
      "  Batch 3,900  of  10,770.\n",
      "  Batch 4,000  of  10,770.\n",
      "  Batch 4,100  of  10,770.\n",
      "  Batch 4,200  of  10,770.\n",
      "  Batch 4,300  of  10,770.\n",
      "  Batch 4,400  of  10,770.\n",
      "  Batch 4,500  of  10,770.\n",
      "  Batch 4,600  of  10,770.\n",
      "  Batch 4,700  of  10,770.\n",
      "  Batch 4,800  of  10,770.\n",
      "  Batch 4,900  of  10,770.\n",
      "  Batch 5,000  of  10,770.\n",
      "  Batch 5,100  of  10,770.\n",
      "  Batch 5,200  of  10,770.\n",
      "  Batch 5,300  of  10,770.\n",
      "  Batch 5,400  of  10,770.\n",
      "  Batch 5,500  of  10,770.\n",
      "  Batch 5,600  of  10,770.\n",
      "  Batch 5,700  of  10,770.\n",
      "  Batch 5,800  of  10,770.\n",
      "  Batch 5,900  of  10,770.\n",
      "  Batch 6,000  of  10,770.\n",
      "  Batch 6,100  of  10,770.\n",
      "  Batch 6,200  of  10,770.\n",
      "  Batch 6,300  of  10,770.\n",
      "  Batch 6,400  of  10,770.\n",
      "  Batch 6,500  of  10,770.\n",
      "  Batch 6,600  of  10,770.\n",
      "  Batch 6,700  of  10,770.\n",
      "  Batch 6,800  of  10,770.\n",
      "  Batch 6,900  of  10,770.\n",
      "  Batch 7,000  of  10,770.\n",
      "  Batch 7,100  of  10,770.\n",
      "  Batch 7,200  of  10,770.\n",
      "  Batch 7,300  of  10,770.\n",
      "  Batch 7,400  of  10,770.\n",
      "  Batch 7,500  of  10,770.\n",
      "  Batch 7,600  of  10,770.\n",
      "  Batch 7,700  of  10,770.\n",
      "  Batch 7,800  of  10,770.\n",
      "  Batch 7,900  of  10,770.\n",
      "  Batch 8,000  of  10,770.\n",
      "  Batch 8,100  of  10,770.\n",
      "  Batch 8,200  of  10,770.\n",
      "  Batch 8,300  of  10,770.\n",
      "  Batch 8,400  of  10,770.\n",
      "  Batch 8,500  of  10,770.\n",
      "  Batch 8,600  of  10,770.\n",
      "  Batch 8,700  of  10,770.\n",
      "  Batch 8,800  of  10,770.\n",
      "  Batch 8,900  of  10,770.\n",
      "  Batch 9,000  of  10,770.\n",
      "  Batch 9,100  of  10,770.\n",
      "  Batch 9,200  of  10,770.\n",
      "  Batch 9,300  of  10,770.\n",
      "  Batch 9,400  of  10,770.\n",
      "  Batch 9,500  of  10,770.\n",
      "  Batch 9,600  of  10,770.\n",
      "  Batch 9,700  of  10,770.\n",
      "  Batch 9,800  of  10,770.\n",
      "  Batch 9,900  of  10,770.\n",
      "  Batch 10,000  of  10,770.\n",
      "  Batch 10,100  of  10,770.\n",
      "  Batch 10,200  of  10,770.\n",
      "  Batch 10,300  of  10,770.\n",
      "  Batch 10,400  of  10,770.\n",
      "  Batch 10,500  of  10,770.\n",
      "  Batch 10,600  of  10,770.\n",
      "  Batch 10,700  of  10,770.\n",
      "  Average training loss: 0.66\n",
      "  Train Accuracy: 95.5644\n",
      "Running evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1370c0b64407429b84d56460e522f30d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test_dataloader:   0%|          | 0/2692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Evaluation Accuracy: 95.9563\n",
      "  f1_score: 86.1253\n",
      "  total_acc: 95.9563\n",
      "======== Epoch 2 / 5 ========\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7927e508bfae40a2a11b6d57f74fc75f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train_dataloader:   0%|          | 0/10770 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   100  of  10,770.\n",
      "  Batch   200  of  10,770.\n",
      "  Batch   300  of  10,770.\n",
      "  Batch   400  of  10,770.\n",
      "  Batch   500  of  10,770.\n",
      "  Batch   600  of  10,770.\n",
      "  Batch   700  of  10,770.\n",
      "  Batch   800  of  10,770.\n",
      "  Batch   900  of  10,770.\n",
      "  Batch 1,000  of  10,770.\n",
      "  Batch 1,100  of  10,770.\n",
      "  Batch 1,200  of  10,770.\n",
      "  Batch 1,300  of  10,770.\n",
      "  Batch 1,400  of  10,770.\n",
      "  Batch 1,500  of  10,770.\n",
      "  Batch 1,600  of  10,770.\n",
      "  Batch 1,700  of  10,770.\n",
      "  Batch 1,800  of  10,770.\n",
      "  Batch 1,900  of  10,770.\n",
      "  Batch 2,000  of  10,770.\n",
      "  Batch 2,100  of  10,770.\n",
      "  Batch 2,200  of  10,770.\n",
      "  Batch 2,300  of  10,770.\n",
      "  Batch 2,400  of  10,770.\n",
      "  Batch 2,500  of  10,770.\n",
      "  Batch 2,600  of  10,770.\n",
      "  Batch 2,700  of  10,770.\n",
      "  Batch 2,800  of  10,770.\n",
      "  Batch 2,900  of  10,770.\n",
      "  Batch 3,000  of  10,770.\n",
      "  Batch 3,100  of  10,770.\n",
      "  Batch 3,200  of  10,770.\n",
      "  Batch 3,300  of  10,770.\n",
      "  Batch 3,400  of  10,770.\n",
      "  Batch 3,500  of  10,770.\n",
      "  Batch 3,600  of  10,770.\n",
      "  Batch 3,700  of  10,770.\n",
      "  Batch 3,800  of  10,770.\n",
      "  Batch 3,900  of  10,770.\n",
      "  Batch 4,000  of  10,770.\n",
      "  Batch 4,100  of  10,770.\n",
      "  Batch 4,200  of  10,770.\n",
      "  Batch 4,300  of  10,770.\n",
      "  Batch 4,400  of  10,770.\n",
      "  Batch 4,500  of  10,770.\n",
      "  Batch 4,600  of  10,770.\n",
      "  Batch 4,700  of  10,770.\n",
      "  Batch 4,800  of  10,770.\n",
      "  Batch 4,900  of  10,770.\n",
      "  Batch 5,000  of  10,770.\n",
      "  Batch 5,100  of  10,770.\n",
      "  Batch 5,200  of  10,770.\n",
      "  Batch 5,300  of  10,770.\n",
      "  Batch 5,400  of  10,770.\n",
      "  Batch 5,500  of  10,770.\n",
      "  Batch 5,600  of  10,770.\n",
      "  Batch 5,700  of  10,770.\n",
      "  Batch 5,800  of  10,770.\n",
      "  Batch 5,900  of  10,770.\n",
      "  Batch 6,000  of  10,770.\n",
      "  Batch 6,100  of  10,770.\n",
      "  Batch 6,200  of  10,770.\n",
      "  Batch 6,300  of  10,770.\n",
      "  Batch 6,400  of  10,770.\n",
      "  Batch 6,500  of  10,770.\n",
      "  Batch 6,600  of  10,770.\n",
      "  Batch 6,700  of  10,770.\n",
      "  Batch 6,800  of  10,770.\n",
      "  Batch 6,900  of  10,770.\n",
      "  Batch 7,000  of  10,770.\n",
      "  Batch 7,100  of  10,770.\n",
      "  Batch 7,200  of  10,770.\n",
      "  Batch 7,300  of  10,770.\n",
      "  Batch 7,400  of  10,770.\n",
      "  Batch 7,500  of  10,770.\n",
      "  Batch 7,600  of  10,770.\n",
      "  Batch 7,700  of  10,770.\n",
      "  Batch 7,800  of  10,770.\n",
      "  Batch 7,900  of  10,770.\n",
      "  Batch 8,000  of  10,770.\n",
      "  Batch 8,100  of  10,770.\n",
      "  Batch 8,200  of  10,770.\n",
      "  Batch 8,300  of  10,770.\n",
      "  Batch 8,400  of  10,770.\n",
      "  Batch 8,500  of  10,770.\n",
      "  Batch 8,600  of  10,770.\n",
      "  Batch 8,700  of  10,770.\n",
      "  Batch 8,800  of  10,770.\n",
      "  Batch 8,900  of  10,770.\n",
      "  Batch 9,000  of  10,770.\n",
      "  Batch 9,100  of  10,770.\n",
      "  Batch 9,200  of  10,770.\n",
      "  Batch 9,300  of  10,770.\n",
      "  Batch 9,400  of  10,770.\n",
      "  Batch 9,500  of  10,770.\n",
      "  Batch 9,600  of  10,770.\n",
      "  Batch 9,700  of  10,770.\n",
      "  Batch 9,800  of  10,770.\n",
      "  Batch 9,900  of  10,770.\n",
      "  Batch 10,000  of  10,770.\n",
      "  Batch 10,100  of  10,770.\n",
      "  Batch 10,200  of  10,770.\n",
      "  Batch 10,300  of  10,770.\n",
      "  Batch 10,400  of  10,770.\n",
      "  Batch 10,500  of  10,770.\n",
      "  Batch 10,600  of  10,770.\n",
      "  Batch 10,700  of  10,770.\n",
      "  Average training loss: 0.66\n",
      "  Train Accuracy: 95.5883\n",
      "Running evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee9400d154c9478eb0c9080ca37b7ee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test_dataloader:   0%|          | 0/2692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Evaluation Accuracy: 95.9563\n",
      "  f1_score: 86.1253\n",
      "  total_acc: 95.9563\n",
      "======== Epoch 3 / 5 ========\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f7698021e8c435e9ba9b72df9153187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train_dataloader:   0%|          | 0/10770 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   100  of  10,770.\n",
      "  Batch   200  of  10,770.\n",
      "  Batch   300  of  10,770.\n",
      "  Batch   400  of  10,770.\n",
      "  Batch   500  of  10,770.\n",
      "  Batch   600  of  10,770.\n",
      "  Batch   700  of  10,770.\n",
      "  Batch   800  of  10,770.\n",
      "  Batch   900  of  10,770.\n",
      "  Batch 1,000  of  10,770.\n",
      "  Batch 1,100  of  10,770.\n",
      "  Batch 1,200  of  10,770.\n",
      "  Batch 1,300  of  10,770.\n",
      "  Batch 1,400  of  10,770.\n",
      "  Batch 1,500  of  10,770.\n",
      "  Batch 1,600  of  10,770.\n",
      "  Batch 1,700  of  10,770.\n",
      "  Batch 1,800  of  10,770.\n",
      "  Batch 1,900  of  10,770.\n",
      "  Batch 2,000  of  10,770.\n",
      "  Batch 2,100  of  10,770.\n",
      "  Batch 2,200  of  10,770.\n",
      "  Batch 2,300  of  10,770.\n",
      "  Batch 2,400  of  10,770.\n",
      "  Batch 2,500  of  10,770.\n",
      "  Batch 2,600  of  10,770.\n",
      "  Batch 2,700  of  10,770.\n",
      "  Batch 2,800  of  10,770.\n",
      "  Batch 2,900  of  10,770.\n",
      "  Batch 3,000  of  10,770.\n",
      "  Batch 3,100  of  10,770.\n",
      "  Batch 3,200  of  10,770.\n",
      "  Batch 3,300  of  10,770.\n",
      "  Batch 3,400  of  10,770.\n",
      "  Batch 3,500  of  10,770.\n",
      "  Batch 3,600  of  10,770.\n",
      "  Batch 3,700  of  10,770.\n",
      "  Batch 3,800  of  10,770.\n",
      "  Batch 3,900  of  10,770.\n",
      "  Batch 4,000  of  10,770.\n",
      "  Batch 4,100  of  10,770.\n",
      "  Batch 4,200  of  10,770.\n",
      "  Batch 4,300  of  10,770.\n",
      "  Batch 4,400  of  10,770.\n",
      "  Batch 4,500  of  10,770.\n",
      "  Batch 4,600  of  10,770.\n",
      "  Batch 4,700  of  10,770.\n",
      "  Batch 4,800  of  10,770.\n",
      "  Batch 4,900  of  10,770.\n",
      "  Batch 5,000  of  10,770.\n",
      "  Batch 5,100  of  10,770.\n",
      "  Batch 5,200  of  10,770.\n",
      "  Batch 5,300  of  10,770.\n",
      "  Batch 5,400  of  10,770.\n",
      "  Batch 5,500  of  10,770.\n",
      "  Batch 5,600  of  10,770.\n",
      "  Batch 5,700  of  10,770.\n",
      "  Batch 5,800  of  10,770.\n",
      "  Batch 5,900  of  10,770.\n",
      "  Batch 6,000  of  10,770.\n",
      "  Batch 6,100  of  10,770.\n",
      "  Batch 6,200  of  10,770.\n",
      "  Batch 6,300  of  10,770.\n",
      "  Batch 6,400  of  10,770.\n",
      "  Batch 6,500  of  10,770.\n",
      "  Batch 6,600  of  10,770.\n",
      "  Batch 6,700  of  10,770.\n",
      "  Batch 6,800  of  10,770.\n",
      "  Batch 6,900  of  10,770.\n",
      "  Batch 7,000  of  10,770.\n",
      "  Batch 7,100  of  10,770.\n",
      "  Batch 7,200  of  10,770.\n",
      "  Batch 7,300  of  10,770.\n",
      "  Batch 7,400  of  10,770.\n",
      "  Batch 7,500  of  10,770.\n",
      "  Batch 7,600  of  10,770.\n",
      "  Batch 7,700  of  10,770.\n",
      "  Batch 7,800  of  10,770.\n",
      "  Batch 7,900  of  10,770.\n",
      "  Batch 8,000  of  10,770.\n",
      "  Batch 8,100  of  10,770.\n",
      "  Batch 8,200  of  10,770.\n",
      "  Batch 8,300  of  10,770.\n",
      "  Batch 8,400  of  10,770.\n",
      "  Batch 8,500  of  10,770.\n",
      "  Batch 8,600  of  10,770.\n",
      "  Batch 8,700  of  10,770.\n",
      "  Batch 8,800  of  10,770.\n",
      "  Batch 8,900  of  10,770.\n",
      "  Batch 9,000  of  10,770.\n",
      "  Batch 9,100  of  10,770.\n",
      "  Batch 9,200  of  10,770.\n",
      "  Batch 9,300  of  10,770.\n",
      "  Batch 9,400  of  10,770.\n",
      "  Batch 9,500  of  10,770.\n",
      "  Batch 9,600  of  10,770.\n",
      "  Batch 9,700  of  10,770.\n",
      "  Batch 9,800  of  10,770.\n",
      "  Batch 9,900  of  10,770.\n",
      "  Batch 10,000  of  10,770.\n",
      "  Batch 10,100  of  10,770.\n",
      "  Batch 10,200  of  10,770.\n",
      "  Batch 10,300  of  10,770.\n",
      "  Batch 10,400  of  10,770.\n",
      "  Batch 10,500  of  10,770.\n",
      "  Batch 10,600  of  10,770.\n",
      "  Batch 10,700  of  10,770.\n",
      "  Average training loss: 0.66\n",
      "  Train Accuracy: 95.5883\n",
      "Running evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89047c06b23d4ee48bb9ef420c096e01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test_dataloader:   0%|          | 0/2692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Evaluation Accuracy: 95.9563\n",
      "  f1_score: 86.1253\n",
      "  total_acc: 95.9563\n",
      "======== Epoch 4 / 5 ========\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c910a4bbfce408f8d33923e3db16af2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train_dataloader:   0%|          | 0/10770 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   100  of  10,770.\n",
      "  Batch   200  of  10,770.\n",
      "  Batch   300  of  10,770.\n",
      "  Batch   400  of  10,770.\n",
      "  Batch   500  of  10,770.\n",
      "  Batch   600  of  10,770.\n",
      "  Batch   700  of  10,770.\n",
      "  Batch   800  of  10,770.\n",
      "  Batch   900  of  10,770.\n",
      "  Batch 1,000  of  10,770.\n",
      "  Batch 1,100  of  10,770.\n",
      "  Batch 1,200  of  10,770.\n",
      "  Batch 1,300  of  10,770.\n",
      "  Batch 1,400  of  10,770.\n",
      "  Batch 1,500  of  10,770.\n",
      "  Batch 1,600  of  10,770.\n",
      "  Batch 1,700  of  10,770.\n",
      "  Batch 1,800  of  10,770.\n",
      "  Batch 1,900  of  10,770.\n",
      "  Batch 2,000  of  10,770.\n",
      "  Batch 2,100  of  10,770.\n",
      "  Batch 2,200  of  10,770.\n",
      "  Batch 2,300  of  10,770.\n",
      "  Batch 2,400  of  10,770.\n",
      "  Batch 2,500  of  10,770.\n",
      "  Batch 2,600  of  10,770.\n",
      "  Batch 2,700  of  10,770.\n",
      "  Batch 2,800  of  10,770.\n",
      "  Batch 2,900  of  10,770.\n",
      "  Batch 3,000  of  10,770.\n",
      "  Batch 3,100  of  10,770.\n",
      "  Batch 3,200  of  10,770.\n",
      "  Batch 3,300  of  10,770.\n",
      "  Batch 3,400  of  10,770.\n",
      "  Batch 3,500  of  10,770.\n",
      "  Batch 3,600  of  10,770.\n",
      "  Batch 3,700  of  10,770.\n",
      "  Batch 3,800  of  10,770.\n",
      "  Batch 3,900  of  10,770.\n",
      "  Batch 4,000  of  10,770.\n",
      "  Batch 4,100  of  10,770.\n",
      "  Batch 4,200  of  10,770.\n",
      "  Batch 4,300  of  10,770.\n",
      "  Batch 4,400  of  10,770.\n",
      "  Batch 4,500  of  10,770.\n",
      "  Batch 4,600  of  10,770.\n",
      "  Batch 4,700  of  10,770.\n",
      "  Batch 4,800  of  10,770.\n",
      "  Batch 4,900  of  10,770.\n",
      "  Batch 5,000  of  10,770.\n",
      "  Batch 5,100  of  10,770.\n",
      "  Batch 5,200  of  10,770.\n",
      "  Batch 5,300  of  10,770.\n",
      "  Batch 5,400  of  10,770.\n",
      "  Batch 5,500  of  10,770.\n",
      "  Batch 5,600  of  10,770.\n",
      "  Batch 5,700  of  10,770.\n",
      "  Batch 5,800  of  10,770.\n",
      "  Batch 5,900  of  10,770.\n",
      "  Batch 6,000  of  10,770.\n",
      "  Batch 6,100  of  10,770.\n",
      "  Batch 6,200  of  10,770.\n",
      "  Batch 6,300  of  10,770.\n",
      "  Batch 6,400  of  10,770.\n",
      "  Batch 6,500  of  10,770.\n",
      "  Batch 6,600  of  10,770.\n",
      "  Batch 6,700  of  10,770.\n",
      "  Batch 6,800  of  10,770.\n",
      "  Batch 6,900  of  10,770.\n",
      "  Batch 7,000  of  10,770.\n",
      "  Batch 7,100  of  10,770.\n",
      "  Batch 7,200  of  10,770.\n",
      "  Batch 7,300  of  10,770.\n",
      "  Batch 7,400  of  10,770.\n",
      "  Batch 7,500  of  10,770.\n",
      "  Batch 7,600  of  10,770.\n",
      "  Batch 7,700  of  10,770.\n",
      "  Batch 7,800  of  10,770.\n",
      "  Batch 7,900  of  10,770.\n",
      "  Batch 8,000  of  10,770.\n",
      "  Batch 8,100  of  10,770.\n",
      "  Batch 8,200  of  10,770.\n",
      "  Batch 8,300  of  10,770.\n",
      "  Batch 8,400  of  10,770.\n",
      "  Batch 8,500  of  10,770.\n",
      "  Batch 8,600  of  10,770.\n",
      "  Batch 8,700  of  10,770.\n",
      "  Batch 8,800  of  10,770.\n",
      "  Batch 8,900  of  10,770.\n",
      "  Batch 9,000  of  10,770.\n",
      "  Batch 9,100  of  10,770.\n",
      "  Batch 9,200  of  10,770.\n",
      "  Batch 9,300  of  10,770.\n",
      "  Batch 9,400  of  10,770.\n",
      "  Batch 9,500  of  10,770.\n",
      "  Batch 9,600  of  10,770.\n",
      "  Batch 9,700  of  10,770.\n",
      "  Batch 9,800  of  10,770.\n",
      "  Batch 9,900  of  10,770.\n",
      "  Batch 10,000  of  10,770.\n",
      "  Batch 10,100  of  10,770.\n",
      "  Batch 10,200  of  10,770.\n",
      "  Batch 10,300  of  10,770.\n",
      "  Batch 10,400  of  10,770.\n",
      "  Batch 10,500  of  10,770.\n",
      "  Batch 10,600  of  10,770.\n",
      "  Batch 10,700  of  10,770.\n",
      "  Average training loss: 0.66\n",
      "  Train Accuracy: 95.5883\n",
      "Running evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca50978acc434d6885b6fdbc57888be9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test_dataloader:   0%|          | 0/2692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Evaluation Accuracy: 95.9563\n",
      "  f1_score: 86.1253\n",
      "  total_acc: 95.9563\n",
      "======== Epoch 5 / 5 ========\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f01ed41da4ee43009d5b70ef74eda26d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train_dataloader:   0%|          | 0/10770 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   100  of  10,770.\n",
      "  Batch   200  of  10,770.\n",
      "  Batch   300  of  10,770.\n",
      "  Batch   400  of  10,770.\n",
      "  Batch   500  of  10,770.\n",
      "  Batch   600  of  10,770.\n",
      "  Batch   700  of  10,770.\n",
      "  Batch   800  of  10,770.\n",
      "  Batch   900  of  10,770.\n",
      "  Batch 1,000  of  10,770.\n",
      "  Batch 1,100  of  10,770.\n",
      "  Batch 1,200  of  10,770.\n",
      "  Batch 1,300  of  10,770.\n",
      "  Batch 1,400  of  10,770.\n",
      "  Batch 1,500  of  10,770.\n",
      "  Batch 1,600  of  10,770.\n",
      "  Batch 1,700  of  10,770.\n",
      "  Batch 1,800  of  10,770.\n",
      "  Batch 1,900  of  10,770.\n",
      "  Batch 2,000  of  10,770.\n",
      "  Batch 2,100  of  10,770.\n",
      "  Batch 2,200  of  10,770.\n",
      "  Batch 2,300  of  10,770.\n",
      "  Batch 2,400  of  10,770.\n",
      "  Batch 2,500  of  10,770.\n",
      "  Batch 2,600  of  10,770.\n",
      "  Batch 2,700  of  10,770.\n",
      "  Batch 2,800  of  10,770.\n",
      "  Batch 2,900  of  10,770.\n",
      "  Batch 3,000  of  10,770.\n",
      "  Batch 3,100  of  10,770.\n",
      "  Batch 3,200  of  10,770.\n",
      "  Batch 3,300  of  10,770.\n",
      "  Batch 3,400  of  10,770.\n",
      "  Batch 3,500  of  10,770.\n",
      "  Batch 3,600  of  10,770.\n",
      "  Batch 3,700  of  10,770.\n",
      "  Batch 3,800  of  10,770.\n",
      "  Batch 3,900  of  10,770.\n",
      "  Batch 4,000  of  10,770.\n",
      "  Batch 4,100  of  10,770.\n",
      "  Batch 4,200  of  10,770.\n",
      "  Batch 4,300  of  10,770.\n",
      "  Batch 4,400  of  10,770.\n",
      "  Batch 4,500  of  10,770.\n",
      "  Batch 4,600  of  10,770.\n",
      "  Batch 4,700  of  10,770.\n",
      "  Batch 4,800  of  10,770.\n",
      "  Batch 4,900  of  10,770.\n",
      "  Batch 5,000  of  10,770.\n",
      "  Batch 5,100  of  10,770.\n",
      "  Batch 5,200  of  10,770.\n",
      "  Batch 5,300  of  10,770.\n",
      "  Batch 5,400  of  10,770.\n",
      "  Batch 5,500  of  10,770.\n",
      "  Batch 5,600  of  10,770.\n",
      "  Batch 5,700  of  10,770.\n",
      "  Batch 5,800  of  10,770.\n",
      "  Batch 5,900  of  10,770.\n",
      "  Batch 6,000  of  10,770.\n",
      "  Batch 6,100  of  10,770.\n",
      "  Batch 6,200  of  10,770.\n",
      "  Batch 6,300  of  10,770.\n",
      "  Batch 6,400  of  10,770.\n",
      "  Batch 6,500  of  10,770.\n",
      "  Batch 6,600  of  10,770.\n",
      "  Batch 6,700  of  10,770.\n",
      "  Batch 6,800  of  10,770.\n",
      "  Batch 6,900  of  10,770.\n",
      "  Batch 7,000  of  10,770.\n",
      "  Batch 7,100  of  10,770.\n",
      "  Batch 7,200  of  10,770.\n",
      "  Batch 7,300  of  10,770.\n",
      "  Batch 7,400  of  10,770.\n",
      "  Batch 7,500  of  10,770.\n",
      "  Batch 7,600  of  10,770.\n",
      "  Batch 7,700  of  10,770.\n",
      "  Batch 7,800  of  10,770.\n",
      "  Batch 7,900  of  10,770.\n",
      "  Batch 8,000  of  10,770.\n",
      "  Batch 8,100  of  10,770.\n",
      "  Batch 8,200  of  10,770.\n",
      "  Batch 8,300  of  10,770.\n",
      "  Batch 8,400  of  10,770.\n",
      "  Batch 8,500  of  10,770.\n",
      "  Batch 8,600  of  10,770.\n",
      "  Batch 8,700  of  10,770.\n",
      "  Batch 8,800  of  10,770.\n",
      "  Batch 8,900  of  10,770.\n",
      "  Batch 9,000  of  10,770.\n",
      "  Batch 9,100  of  10,770.\n",
      "  Batch 9,200  of  10,770.\n",
      "  Batch 9,300  of  10,770.\n",
      "  Batch 9,400  of  10,770.\n",
      "  Batch 9,500  of  10,770.\n",
      "  Batch 9,600  of  10,770.\n",
      "  Batch 9,700  of  10,770.\n",
      "  Batch 9,800  of  10,770.\n",
      "  Batch 9,900  of  10,770.\n",
      "  Batch 10,000  of  10,770.\n",
      "  Batch 10,100  of  10,770.\n",
      "  Batch 10,200  of  10,770.\n",
      "  Batch 10,300  of  10,770.\n",
      "  Batch 10,400  of  10,770.\n",
      "  Batch 10,500  of  10,770.\n",
      "  Batch 10,600  of  10,770.\n",
      "  Batch 10,700  of  10,770.\n",
      "  Average training loss: 0.66\n",
      "  Train Accuracy: 95.5883\n",
      "Running evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b47a54f3350541d788e237b7f11b5870",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test_dataloader:   0%|          | 0/2692 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Evaluation Accuracy: 95.9563\n",
      "  f1_score: 86.1253\n",
      "  total_acc: 95.9563\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "for epoch_i in tqdm(range(args.epochs), desc = 'epoch', total = args.epochs):\n",
    "\n",
    "    #train\n",
    "    ser_model.train()\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, args.epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    total_loss = 0\n",
    "    train_acc_sum = 0\n",
    "    train_loss = []\n",
    "    for step, (data, labels) in tqdm(enumerate(train_dataloader), desc = 'train_dataloader', total = len(train_dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        if step % 100 == 0 and not step == 0:\n",
    "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
    "        \n",
    "        speech = data.cuda()\n",
    "        labels = labels.cuda()        \n",
    "\n",
    "        outputs = ser_model(speech)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        train_loss.append(total_loss/(step+1))\n",
    "\n",
    "        targets = labels.detach().cpu().numpy()\n",
    "        preds = outputs.detach().cpu().numpy() > 0.5\n",
    "        train_acc = np.equal(targets, preds).sum()/7\n",
    "        train_acc_sum += train_acc\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "    print(f'  Average training loss: {avg_train_loss:.2f}')\n",
    "    print(f'  Train Accuracy: {100 * train_acc_sum / len(train_dataloader.dataset):.4f}')\n",
    "\n",
    "    #validation\n",
    "    with torch.no_grad():\n",
    "        ser_model.eval()\n",
    "        print('Running evaluation...')\n",
    "\n",
    "        val_acc_sum = 0\n",
    "        targets_list = []\n",
    "        preds_list = []\n",
    "        for data, labels in tqdm(test_dataloader, desc = 'test_dataloader', total = len(test_dataloader)):\n",
    "\n",
    "            speech = data.cuda()\n",
    "            labels = labels.cuda()\n",
    "            \n",
    "            outputs = ser_model(speech)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            targets = labels.detach().cpu().numpy()\n",
    "            preds = outputs.detach().cpu().numpy() > 0.5\n",
    "            val_acc = np.equal(targets, preds).sum()/7\n",
    "            val_acc_sum += val_acc\n",
    "            targets_list.append(targets)\n",
    "            preds_list.append(preds)\n",
    "\n",
    "\n",
    "        targets_list = np.concatenate(targets_list, axis = 0)\n",
    "        preds_list = np.concatenate(preds_list, axis = 0)\n",
    "        f1_scores = f1_score(targets_list, preds_list, average=\"micro\") * 100.0\n",
    "        total_acc = (preds_list == targets_list).mean() * 100.0\n",
    "\n",
    "    print(f'  Evaluation Accuracy: {100 * val_acc_sum / len(test_dataloader.dataset):.4f}')\n",
    "    print(f'  f1_score: {f1_scores:.4f}')\n",
    "    print(f'  total_acc: {total_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'model/wac2vec_emotion_classification_model_batch1.pt'\n",
    "torch.save(ser_model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
